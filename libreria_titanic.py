# -*- coding: utf-8 -*-
"""Libreria_Titanic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/francoquintanilla0/M2-ML_Library/blob/main/Libreria_Titanic.ipynb
"""

from google.colab import drive
drive.mount("/content/gdrive")

# TODAS LAS LIBRERIAS
import pandas as pd
import seaborn as sns
import numpy as np
import matplotlib.pyplot as plt

# Leemos el archivo
df = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/Documentos IA/titanic/train.csv', index_col='PassengerId')
df.head()

# Sacamos el tamaño del archivo
df.shape

# Contamos cuantos NaN existen en el dataset de cada grupo
df.isna().sum()

# Como hay demasiados datos faltantes de "Cabin", eliminamos esa columna
df = df.drop('Cabin', axis=1)

# En "Age" tenemos 2 opcines, borrar los datos NaNs o rellenarlos con la media de los datos que tenemos
# Opté por eliminarlos, ya que la edad si puede ser un factor importante al determinar si un pasajero
# sobrevive o no.

# En el caso de "Embarked" como solo son 2, igual eliminamos esas filas.
df = df.dropna()

# Volvemos a ver si quedan más NaNs en el data set.
df.isna().sum()

# Vemos cual es el tamaño del data set limpio
df.shape

# Vemos que perdimos un total de 179 datos
891 - 712

# Vemos el dataset limpio
df.head()

# Buscamos datos duplicados en "Names", es decir nombres duplicados
listNames = df['Name'].tolist()

dup = {x for x in listNames if listNames.count(x) > 1}
print(dup)
# NO tenemos nombres duplicados, por lo que a pesar de que en una familia hubieran
# estado (ej. 5 personas), solo se reporto 1 (ya sea muerte o sobreviviente)

# Hacemos un poco de reducción de dimensiones, por lo que podemos sumar los grupos de 
# "SibSp" y	"Parch" sacando un total de integrantes. El 1 se suma por si alguien va solo 
# (la persona que sale en "Name")

# Hacemos esto por que puede ser que el factor de ver por tu vida o por la de alguien de tu familia
# puede ser que afecte en el razonamiento de las personas
df['Tots in Group'] = df['SibSp'] + df['Parch'] + 1

# Con esta relación, entonces podemos eliminar las columnas de "SibSp" y	"Parch".
df = df.drop(['SibSp', 'Parch'], axis=1)

# Para limpiar más nuestros datos, eliminamos datos irrelevantes como
# "Ticket", "Fare" y el "Name".
df = df.drop(['Ticket', 'Fare', 'Name'], axis=1)

# Volvemos a ver nuestro data set actualizado
df.head()

# Checamos el minimo y maximo valor de las edades
print(min(df['Age']))
print(max(df['Age']))

# Como tenemos un extenso rango de edades, los juntamos en un "Rango" de edades.
for i in df:
    df['Age Categ'] = pd.cut(df['Age'], bins=[0, 5, 12, 18, 35, 60, 81], \
                           labels=['Bebe', 'Niño', 'Adolecente', 'Adulto Joven', 'Adulto Mayor', 'Anciano'])

# Hecho esto, podemos eliminar la columan de las edades numericas
df = df.drop('Age', axis=1)

# Vemos los datos
df.head(10)

"""Hasta Aqui LLevo 18/ago/2022. TRY 1

Seguir aqui abajo después...
"""

# Visualizaciones de proporciones de diferencias.
fig, axes = plt.subplots(3, 2, figsize=(22,14))

sns.barplot(x='Sex', y='Survived', data=df, ax=axes[0, 0])
sns.barplot(x='Age Categ', y='Survived', data=df, ax=axes[1, 0])
sns.barplot(x='Pclass', y='Survived', data=df, ax=axes[2, 0])
sns.barplot(x='Embarked', y='Survived', data=df, ax=axes[0, 1])
sns.barplot(x='Tots in Group', y='Survived', data=df, ax=axes[1, 1])

# Figuras con scatter para poder tener una mejor visualización de los datos, por si es que existe
# un outlier.
fig, axes = plt.subplots(3, 2, figsize=(20,12))
sns.scatterplot(x='PassengerId', y='Age Categ', data=df, ax=axes[0, 0])
sns.scatterplot(x='PassengerId', y='Survived', data=df, ax=axes[1, 0])
sns.scatterplot(x='PassengerId', y='Pclass', data=df, ax=axes[2, 0])
sns.scatterplot(x='PassengerId', y='Sex', data=df, ax=axes[0, 1])
sns.scatterplot(x='PassengerId', y='Embarked', data=df, ax=axes[1, 1])
sns.scatterplot(x='PassengerId', y='Tots in Group', data=df, ax=axes[2, 1])

# Vamos a sumar Tots in group para ver si son da el mismo resultado que el shape del dataset
# Para ver si las personas que vienen en familia tambien están registradas, o si solo se registro
# a un familiar principal.
df['Tots in Group'].sum()

# Como vimos tambien con los duplicados, hay más personas de las que están registradas
# y eso abre muchas más preguntas

# Ahora, con los datos limpios y clasificados, necesitamos hacerlos numericos, por
# lo que la función de get_dummies de python nos va a ayudar a hacer más columnas
# numericas de TRUE-FALSE después generar el modelo.

df = pd.get_dummies(df, columns = ["Sex"], drop_first = False)
df = pd.get_dummies(df, columns = ["Age Categ"], drop_first = False)
df = pd.get_dummies(df, columns = ["Pclass"], drop_first = False)
df = pd.get_dummies(df, columns = ["Embarked"], drop_first = False)

# Vemos el nuevo dataframe
df.head()

"""Ya tenemos todas las categorias en numeros. (TRY 2)

Ahora creo que empezamos a buscar que modelo se acomodaría mejor, pero creo que sería el de logistic regression por tener 1 y 0. 

Por lo que no se si borrar la categoria de "Tots in Group", pero creo que si después queremos separar nuestro modelo en clusters, ese aspecto de integrantes de la familia nos podría ayudar a dividirlo en K-means.

"""

# Buscar logistic regression en python (sklearn)

"""Tenemos que importar el TEST data set, para usarlo en el modelo."""

# Para el modelo, tenemos que traer los datos que va a predecir, es decir el test.
df_test = pd.read_csv('/content/gdrive/MyDrive/Colab Notebooks/Documentos IA/titanic/test.csv', index_col='PassengerId')
df_test.head()

# Tenemos que volver a hacer toda la limpia y conjunto de datos que hicimos con el data de train

# Sacamos su tamaño
df_test.shape

# Vemos cuantos NaNs tiene
df_test.isna().sum()

# Quitamos "Cabin" por 2 cosas, por que tiene demasiados NaNs y por que ya lo habiamos eliminado
# del train data.
df_test = df_test.drop('Cabin', axis=1)

# Tambien después quitamos todos los NaNs
df_test = df_test.dropna()

# Vemos si quedan NaNs en el dataset del test
df_test.isna().sum()

df_test.head()

# Hacemos la misma limpia que antes
df_test['Tots in Group'] = df_test['SibSp'] + df_test['Parch'] + 1

# Con esta relación, entonces podemos eliminar las columnas de "SibSp" y	"Parch".
df_test = df_test.drop(['SibSp', 'Parch'], axis=1)

# Para limpiar más nuestros datos, eliminamos datos irrelevantes como
# "Ticket", "Fare" y el "Name".
df_test = df_test.drop(['Ticket', 'Fare', 'Name'], axis=1)

# Volvemos a ver nuestro data set actualizado
df_test.head()

# Hacemos lo del "Rango" de edades.
for i in df_test:
    df_test['Age Categ'] = pd.cut(df_test['Age'], bins=[0, 5, 12, 18, 35, 60, 81], \
                           labels=['Bebe', 'Niño', 'Adolecente', 'Adulto Joven', 'Adulto Mayor', 'Anciano'])

# Hecho esto, podemos eliminar la columan de las edades numericas
df_test = df_test.drop('Age', axis=1)

# Vemos los datos
df_test.head(10)

# Figuras con scatter para poder tener una mejor visualización de los datos, por si es que existe
# un outlier. del TEST data
fig, axes = plt.subplots(3, 2, figsize=(20,12))
sns.scatterplot(x='PassengerId', y='Age Categ', data=df_test, ax=axes[0, 0])
sns.scatterplot(x='PassengerId', y='Pclass', data=df_test, ax=axes[1, 0])
sns.scatterplot(x='PassengerId', y='Sex', data=df_test, ax=axes[2, 0])
sns.scatterplot(x='PassengerId', y='Embarked', data=df_test, ax=axes[0, 1])
sns.scatterplot(x='PassengerId', y='Tots in Group', data=df_test, ax=axes[1, 1])

# Aqui vemos que en el caso de "Tots in group" si existe un outlier en comparación con 
# nuetsro train data, por lo que para dejarlos iguales, vamos a eliminarlo.
print(df_test[df_test['Tots in Group'] > 8])
df_test = df_test.drop(index=1252)

# Cehcamos si se eliminaron
sns.scatterplot(x='PassengerId', y='Tots in Group', data=df_test)

# Ya con el outlier y los datos eliminados, checamos otra vez el head de nuetstros datos
df_test.head()

# Con los datos limpios, podemos convertir todos nuestros datos otra vez en 0 y 1,
# para poder hacerle fit con nuestro modelo de regresion logistica.
df_test = pd.get_dummies(df_test, columns = ["Sex"], drop_first = False)
df_test = pd.get_dummies(df_test, columns = ["Age Categ"], drop_first = False)
df_test = pd.get_dummies(df_test, columns = ["Pclass"], drop_first = False)
df_test = pd.get_dummies(df_test, columns = ["Embarked"], drop_first = False)

# Vemos el nuevo dataframe
df_test.head()

# Checamos los 2 dataframes para ver si son iguales, es decir, imprimimos otra vez el de
# train para checar similitudes
df.head()

"""Ya con los 2 dataframes limpios e iguales (solo el de train tiene obvaiemnte la columna de los sobrevivientes, por que con eso se va a entrenar, es decir, ese es nuestro goal) podemos implementar el modelo."""

# Importamos lo necesario para el modelo de DecisionTreeClassifier de scikit learn
from sklearn import ensemble
from sklearn.ensemble import RandomForestClassifier
import graphviz
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import cross_val_predict

# Definimos variables del modelo con nuesta data
seed = 1800
testp = 0.25

# Nuestra variable objetivo, es decir, lo que buscamos
dfy = df['Survived']

# Con esto, eliminamos del train data, esa columna
dfx = df.drop('Survived',axis=1)

# Dividimos nuestro modelo con el data de entrenamiento con difrentes variables
x, x_test, y, y_test = \
train_test_split(dfx, dfy, test_size=testp, random_state=seed)

# RandomForestClassifier
model = RandomForestClassifier(n_estimators=20, random_state=seed)
model.fit(x, y)

# Hacemos prodeciones
y_pred = model.predict(x_test)
print("Accuracy:", accuracy_score(y_test, y_pred))

feature_names = ["Tots in Group", "Female", "Male", "Bebe", "Niño",\
          "Adolecente", "Adulto Joven", "Adulto Mayor",\
          "Anciano", "Class 1", "Class 2", "Class 3", "Embarked C", "Embarked Q", "Embarked S"]

class_names = ["No Survived", "Survived"]

# Sacamos la importancia de las variables
importance = pd.Series(model.feature_importances_, index=feature_names)

# Graficamos
sns.barplot(x=importance, y=importance.index)
plt.xlabel('Importancia de las variables')
plt.ylabel('Variable')
plt.title('Importancia de las variables')
plt.show()

from sklearn.model_selection import learning_curve
from sklearn.metrics import confusion_matrix

# CM
y_pred = cross_val_predict(model, x, y, cv=10)
sns.heatmap(confusion_matrix(y, y_pred), annot=True, fmt='3.0f')
plt.show()

# Learning curve
train_sizes, train_scores, test_scores = learning_curve(model, x, y, n_jobs=-1, train_sizes=np.linspace(.1, 1.0, 5), verbose=0)

train_scores_mean = np.mean(train_scores, axis=1)
train_scores_std = np.std(train_scores, axis=1)
test_scores_mean = np.mean(test_scores, axis=1)
test_scores_std = np.std(test_scores, axis=1)
    
plt.figure()
plt.title("Random Forest")
plt.xlabel("Training examples")
plt.ylabel("Score")
plt.gca().invert_yaxis()
    
plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color="r")
plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color="g")

plt.plot(train_sizes, train_scores_mean, 'o-', color="r", label="Training score")
plt.plot(train_sizes, test_scores_mean, 'o-', color="g", label="Test score")
plt.legend(loc="best")
    
plt.ylim(-.1,1.1)
plt.show()